{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f758d7-86be-40e5-831a-2efac3299c9c",
   "metadata": {},
   "source": [
    "## RAVE evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8693808e-84d9-4a9f-a567-5d38576c2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb9e9d0-dd2e-482a-ac79-325f319ba922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/.pyenv/versions/3.8.8/envs/electroml/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deep_eurorack_control.models.rave import RAVE\n",
    "from deep_eurorack_control.datasets.data_loaders import nsynth_data_loader\n",
    "from deep_eurorack_control.config import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b008d-452d-41dd-a717-6f6553f9a85f",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48205e76-5a41-496b-820a-4eb00c113816",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"/home/sarah/Projects/master_atiam/pam/deep-eurorack-control/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4d867-a9fa-4232-9b20-4abfffd92924",
   "metadata": {},
   "source": [
    "#### VAE n_band = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86751d72-a63b-4bb9-ba10-1c967c5fe7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "check_vae_1 = \"n_synth_rave__n_band_1__latent_128__sr_16000__noise_False__init_weights_True__b_8__lr_0.0001__e_150__e_warmup_150__seed_0__vae.pt\"\n",
    "checkpoint_vae_1 = torch.load(os.path.join(models_dir, check_vae_1), map_location=torch.device('cpu'))\n",
    "\n",
    "vae_1 = RAVE(\n",
    "    n_band=1,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=False,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "vae_1.encoder.load_state_dict(checkpoint_vae_1['encoder_state_dict'])\n",
    "vae_1.decoder.load_state_dict(checkpoint_vae_1['decoder_state_dict'])\n",
    "vae_1.encoder.eval()\n",
    "vae_1.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9dbab-5320-47c1-bd4e-02575399931a",
   "metadata": {},
   "source": [
    "#### VAE n_band = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f283af5-1ea2-44c2-8427-786402e6203e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/sarah/Projects/master_atiam/pam/deep-eurorack-control/models/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8420/142384321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheck_vae_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint_vae_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_vae_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m vae_4 = RAVE(\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_band\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/envs/electroml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/envs/electroml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.8/envs/electroml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/sarah/Projects/master_atiam/pam/deep-eurorack-control/models/'"
     ]
    }
   ],
   "source": [
    "check_vae_4 = \"\"\n",
    "checkpoint_vae_4 = torch.load(os.path.join(models_dir, check_vae_4), map_location=torch.device('cpu'))\n",
    "\n",
    "vae_4 = RAVE(\n",
    "    n_band=4,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=False,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "vae_4.encoder.load_state_dict(checkpoint_vae_4['encoder_state_dict'])\n",
    "vae_4.decoder.load_state_dict(checkpoint_vae_4['decoder_state_dict'])\n",
    "vae_4.encoder.eval()\n",
    "vae_4.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9df425-8350-44f5-b3f6-bf51cf5ad6ab",
   "metadata": {},
   "source": [
    "#### VAE n_band = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3174cca-a2d8-4180-99af-33ca0db14711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "check_vae_8 = \"n_synth_rave__n_band_8__latent_128__sr_16000__noise_False__init_weights_True__b_8__lr_0.0001__e_150__e_warmup_150__seed_0__vae.pt\"\n",
    "checkpoint_vae_8 = torch.load(os.path.join(models_dir, check_vae_8), map_location=torch.device('cpu'))\n",
    "\n",
    "vae_8 = RAVE(\n",
    "    n_band=8,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=False,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "vae_8.encoder.load_state_dict(checkpoint_vae_8['encoder_state_dict'])\n",
    "vae_8.decoder.load_state_dict(checkpoint_vae_8['decoder_state_dict'])\n",
    "vae_8.encoder.eval()\n",
    "vae_8.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060839d6-b136-440a-b14a-1d4ac596b1fb",
   "metadata": {},
   "source": [
    "#### VAE n_band = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d1894f-ef4e-4ff7-8a60-1e7dc169e744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "check_vae_16 = \"n_synth_rave__n_band_16__latent_128__sr_16000__noise_False__init_weights_True__b_8__lr_0.0001__e_150__e_warmup_150__seed_0__vae.pt\"\n",
    "checkpoint_vae_16 = torch.load(os.path.join(models_dir, check_vae_16), map_location=torch.device('cpu'))\n",
    "\n",
    "vae_16 = RAVE(\n",
    "    n_band=16,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=False,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "vae_16.encoder.load_state_dict(checkpoint_vae_16['encoder_state_dict'])\n",
    "vae_16.decoder.load_state_dict(checkpoint_vae_16['decoder_state_dict'])\n",
    "vae_16.encoder.eval()\n",
    "vae_16.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941bfac9-77b9-46a6-a129-a3d0dabbfa72",
   "metadata": {},
   "source": [
    "#### VAE n_band = 8 GAN without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a70d3e-285b-40d2-8539-35df9f3a1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "check_rave_8_no_noise = \"n_synth_rave__n_band_8__latent_128__sr_16000__noise_False__init_weights_True__b_8__lr_0.0001__e_250__e_warmup_150__vae.pt\"\n",
    "checkpoint_rave_no_noise = torch.load(os.path.join(models_dir, check_rave_8_no_noise), map_location=torch.device('cpu'))\n",
    "\n",
    "rave_no_noise = RAVE(\n",
    "    n_band=8,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=False,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "rave_no_noise.encoder.load_state_dict(checkpoint_rave_no_noise['encoder_state_dict'])\n",
    "rave_no_noise.decoder.load_state_dict(checkpoint_rave_no_noise['decoder_state_dict'])\n",
    "rave_no_noise.encoder.eval()\n",
    "rave_no_noise.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b923437-6b26-4728-9719-1f62cbef4dbb",
   "metadata": {},
   "source": [
    "#### VAE n_band = 8 GAN with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9541a00-312a-4d61-b236-4d14fc192159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "check_rave_8_noise = \"n_synth_rave__n_band_8__latent_128__sr_16000__noise_True__init_weights_True__b_8__lr_0.0001__e_250__e_warmup_150__vae.pt\"\n",
    "checkpoint_rave_noise = torch.load(os.path.join(models_dir, check_rave_8_noise), map_location=torch.device('cpu'))\n",
    "\n",
    "rave_noise = RAVE(\n",
    "    n_band=8,\n",
    "    latent_dim=128,\n",
    "    hidden_dim=64,\n",
    "    sampling_rate=16000,\n",
    "    use_noise=True,\n",
    "    init_weights=True\n",
    ")\n",
    "\n",
    "rave_noise.encoder.load_state_dict(checkpoint_rave_noise['encoder_state_dict'])\n",
    "rave_noise.decoder.load_state_dict(checkpoint_rave_noise['decoder_state_dict'])\n",
    "rave_noise.encoder.eval()\n",
    "rave_noise.decoder.eval()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd1981-0993-446f-8ca4-c398002bd31d",
   "metadata": {},
   "source": [
    "## Load Test Dataset Nsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31e5c89-628b-4244-8012-838a46501799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = nsynth_data_loader(\n",
    "    batch_size=8,\n",
    "    data_dir=\"/home/sarah/Projects/master_atiam/pam/deep-eurorack-control/data\",\n",
    "    audio_dir=\"/home/sarah/Projects/master_atiam/pam/nsynth-test/audio\",\n",
    "    nsynth_json=\"nsynth_string_test.json\",\n",
    "    valid_ratio=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879bd50-3b27-480f-85fd-e310d3b0bad1",
   "metadata": {},
   "source": [
    "### Latent space analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c5bc179-1613-4b74-af99-37221f2f1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_pca_analysis(model, test_loader, latent_dim=128):\n",
    "    z_list = []\n",
    "    s_list = []\n",
    "    for s, _ in test_loader:\n",
    "        s_list.append(s)\n",
    "        s = torch.reshape(s, (s.shape[0], 1, -1))\n",
    "\n",
    "        # 1. multi band decomposition pqmf\n",
    "        s = model.multi_band_decomposition(s)\n",
    "\n",
    "        # 2. Encode data\n",
    "        mean, var = model.encoder(s)\n",
    "\n",
    "        # z, _ = model.reparametrize(mean, var)\n",
    "        z = mean\n",
    "        z_list.append(z)\n",
    "    \n",
    "    z_valid = torch.cat(z_list, 0)\n",
    "    print(f\"nb samples : {z_valid.shape[0]}\")\n",
    "    z_valid = z_valid.reshape(-1, z_valid.shape[1])\n",
    "    latent_mean = z_valid.mean(0)\n",
    "    z_center = z_valid - latent_mean\n",
    "    \n",
    "    pca = PCA(latent_dim).fit(z_center.detach().cpu().numpy())\n",
    "    components = pca.components_\n",
    "    components = torch.from_numpy(components).to(z_center)\n",
    "\n",
    "    var = pca.explained_variance_ / np.sum(pca.explained_variance_)\n",
    "    var = np.cumsum(var)\n",
    "    \n",
    "    var_percent = [.8, .9, .95, .99]\n",
    "    for p in var_percent:\n",
    "        print(f\"{p}%_manifold\", np.argmax(var > p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc1e3fa-12f9-41f8-974a-6f44943eb5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb samples : 306\n",
      "0.8%_manifold 2\n",
      "0.9%_manifold 2\n",
      "0.95%_manifold 5\n",
      "0.99%_manifold 30\n"
     ]
    }
   ],
   "source": [
    "latent_space_pca_analysis(rave_noise, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7109235-f076-40c8-a7bc-38558734c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb samples : 306\n",
      "0.8%_manifold 0\n",
      "0.9%_manifold 1\n",
      "0.95%_manifold 1\n",
      "0.99%_manifold 12\n"
     ]
    }
   ],
   "source": [
    "latent_space_pca_analysis(rave_no_noise, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "662bfae7-71c4-497c-94b0-57fd5e79c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb samples : 306\n",
      "0.8%_manifold 0\n",
      "0.9%_manifold 1\n",
      "0.95%_manifold 2\n",
      "0.99%_manifold 12\n"
     ]
    }
   ],
   "source": [
    "latent_space_pca_analysis(vae_8, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdaf100-5a52-4c0c-a88d-3b822afc1a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb samples : 306\n",
      "0.8%_manifold 1\n",
      "0.9%_manifold 4\n",
      "0.95%_manifold 11\n",
      "0.99%_manifold 37\n"
     ]
    }
   ],
   "source": [
    "latent_space_pca_analysis(vae_16, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8a50a-a30f-4223-b924-4b69e8376dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4958e74d-ca4f-4dd0-b3f3-40ddc465c564",
   "metadata": {},
   "source": [
    "## Reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4fbea4-504a-440a-8f17-3803a53edad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea6957a-9c5a-4ee2-bc07-c936bdc5772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):\n",
    "    return torch.log(torch.clamp(x, min=clip_val) * C)\n",
    "\n",
    "def spectral_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_compression_torch(magnitudes)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f24b47-fc36-41f1-a729-ec0f1ebaefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectrogram(x, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False):\n",
    "    #if torch.min(x) < -1.:\n",
    "    #    print('min value is ', torch.min(x))\n",
    "    #if torch.max(x) > 1.:\n",
    "    #    print('max value is ', torch.max(x))\n",
    "\n",
    "    global mel_basis, hann_window, device\n",
    "    if fmax not in mel_basis:\n",
    "        mel = librosa_mel_fn(sampling_rate, n_fft, num_mels, fmin, fmax)\n",
    "        mel_basis[str(fmax)+'_'+str(x.device)] = torch.from_numpy(mel).float().to(x.device)\n",
    "        hann_window[str(x.device)] = torch.hann_window(win_size).to(x.device)\n",
    "\n",
    "    \n",
    "    x = torch.nn.functional.pad(x.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')\n",
    "    x = x.squeeze(1)\n",
    "\n",
    "    melspectro = torch.stft(x, n_fft, hop_length=hop_size, win_length=win_size, window=hann_window[str(x.device)],\n",
    "                      center=center, pad_mode='reflect', normalized=False, onesided=True)\n",
    "\n",
    "    melspectro = torch.sqrt(melspectro.pow(2).sum(-1)+(1e-9))\n",
    "\n",
    "    melspectro = torch.matmul(mel_basis[str(fmax)+'_'+str(x.device)], melspectro)\n",
    "    melspectro = spectral_normalize_torch(melspectro)\n",
    "\n",
    "    return melspectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a63241a-162c-40ad-9bb0-8fad0c3abe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram_loss(x, x_gen, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False):\n",
    "    \n",
    "    x_mel = mel_spectrogram(x, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center)\n",
    "    x_gen_mel = mel_spectrogram(x_gen, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center)\n",
    "    \n",
    "    loss_melspectro = F.l1_loss(x_mel, x_gen_mel)\n",
    "\n",
    "    return loss_melspectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c74c8a-1b42-486d-b537-0dcd05d4f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_basis = {}\n",
    "hann_window = {}\n",
    "\n",
    "n_fft = 1024\n",
    "num_mels = 80\n",
    "sampling_rate = 48000\n",
    "hop_size = 256\n",
    "win_size = 1024\n",
    "fmin = 0\n",
    "fmax = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac3a49d-fb8c-4328-92eb-ef28c15af95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarah/.pyenv/versions/3.8.8/envs/electroml/lib/python3.8/site-packages/torch/functional.py:471: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:664.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, pitch = next(iter(test_loader))\n",
    "melspectrogram_loss(audio, audio, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74598436-2409-42da-84d8-f1ad45d616cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for x, _ in test_loader:\n",
    "        x_list.append(x)\n",
    "        x = torch.reshape(x, (x.shape[0], 1, -1))\n",
    "\n",
    "        # 1. multi band decomposition pqmf\n",
    "        x = model.multi_band_decomposition(x)\n",
    "\n",
    "        # 2. Encode data\n",
    "        mean, var = model.encoder(x)\n",
    "\n",
    "        # z, _ = model.reparametrize(mean, var)\n",
    "        z = mean\n",
    "        \n",
    "        y = model.decoder(z)\n",
    "        y = model.multi_band_decomposition.inverse(y)\n",
    "        y = y.reshape(y.shape[0], -1)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    x_test = torch.cat(x_list, 0)\n",
    "    y_test = torch.cat(y_list, 0)\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d2214-617b-458c-8099-aeb42f96e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = inference(rave_noise, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994150d2-2c90-4ccf-bbf0-ff3e8d947ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_mel_spec(model, test_loader):\n",
    "    mel_loss = []\n",
    "    for s, _ in test_loader:\n",
    "        x = torch.reshape(s, (s.shape[0], 1, -1))\n",
    "\n",
    "        # 1. multi band decomposition pqmf\n",
    "        x = model.multi_band_decomposition(x)\n",
    "\n",
    "        # 2. Encode data\n",
    "        mean, var = model.encoder(x)\n",
    "\n",
    "        # z, _ = model.reparametrize(mean, var)\n",
    "        z = mean\n",
    "        \n",
    "        y = model.decoder(z)\n",
    "        y = model.multi_band_decomposition.inverse(y)\n",
    "        y = y.reshape(y.shape[0], y.shape[-1])\n",
    "        #res.append(y.reshape(-1).to(\"cpu\").detach().numpy())\n",
    "        mel_basis = {}\n",
    "        hann_window = {}\n",
    "        loss_i = melspectrogram_loss(s, y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False)\n",
    "        mel_loss.append(torch.mean(loss_i))\n",
    "    return res     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9520baa-c047-44c1-98cd-76bf79535ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value is  tensor(-1.0293, grad_fn=<MinBackward1>)\n",
      "max value is  tensor(1.1945, grad_fn=<MaxBackward1>)\n",
      "min value is  tensor(-1.1362, grad_fn=<MinBackward1>)\n",
      "max value is  tensor(1.2580, grad_fn=<MaxBackward1>)\n",
      "min value is  tensor(-1.0193, grad_fn=<MinBackward1>)\n",
      "max value is  tensor(1.1029, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_mel_spec(rave_noise, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb045c-f79e-4e2b-843b-d88a5efcee4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
